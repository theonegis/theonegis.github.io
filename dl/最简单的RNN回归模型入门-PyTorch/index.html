<!DOCTYPE html>
<html lang="zh-CN">
    <head prefix="og: https://ogp.me/ns#">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="color-scheme" content="light dark">
  <meta name="msvalidate.01" content="E0719258D9996F545A834108E5C74A7F" />
  <meta name="baidu-site-verification" content="codeva-mge5JyeFyt" />
  <meta name="google-site-verification" content="T311rYZ3FLiMQxxjBMtkGeur0fjf0m9dLn4x7jS5HUY" />
  
  <title>最简单的RNN回归模型入门(PyTorch) - 阿振的个人主页</title>
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    <link rel='manifest' href='/manifest.json'>
  

  
  
  
  <meta property="og:title" content="最简单的RNN回归模型入门(PyTorch) - 阿振的个人主页" />
  
  <meta property="og:type" content="article" />
  
  <meta property="og:url" content="http://theonegis.github.io/dl/%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84RNN%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8-PyTorch/index.html" />
  
  <meta property="og:image" content="/favicon.png" />
  
  <meta property="og:article:published_time" content="2019-03-02T04:46:15.000Z" />
  
  <meta property="og:article:author" content="阿振" />
  
  

  
<link rel="stylesheet" href="/css/var.css">

  
<link rel="stylesheet" href="/css/main.css">

  
<link rel="stylesheet" href="/css/typography.css">

  
<link rel="stylesheet" href="/css/code-highlighting.css">

  
<link rel="stylesheet" href="/css/components.css">

  
<link rel="stylesheet" href="/css/nav.css">

  
<link rel="stylesheet" href="/css/paginator.css">

  
<link rel="stylesheet" href="/css/footer.css">

  
<link rel="stylesheet" href="/css/post-list.css">

  
  
<link rel="stylesheet" href="/css/rainbow-banner.css">

  
  
  
<link rel="stylesheet" href="/css/toc.css">

  
  
  
  
  
<link rel="stylesheet" href="/css/post.css">

  
  
  
  
  

  
  <meta name="msvalidate.01" content="E0719258D9996F545A834108E5C74A7F" />
  <meta name="baidu-site-verification" content="codeva-mge5JyeFyt" />
  <meta name="google-site-verification" content="T311rYZ3FLiMQxxjBMtkGeur0fjf0m9dLn4x7jS5HUY" />
<meta name="generator" content="Hexo 5.4.2"></head>
    <body
        data-color-scheme="auto"
        data-uppercase-categories="true"
        
        data-rainbow-banner="true"
        data-rainbow-banner-shown="auto"
        data-rainbow-banner-month="6"
        data-rainbow-banner-colors="#e50000,#ff8d00,#ffee00,#008121,#004cff,#760188"
        
        data-config-root="/"
        
        data-toc="true"
        data-toc-max-depth="2"
        
        
    >
        <nav id="theme-nav">
    <div class="inner">
        <a class="title" href="/">TheOneGIS</a>
        <div class="nav-arrow"></div>
        <div class="nav-items">
            <a class="nav-item nav-item-home" href="/">Home</a>
            
            
            <a class="nav-item" href="/">Home</a>
            
            
            
            <a class="nav-item" href="/archives">Archives</a>
            
            
            
            <a class="nav-item" href="/categories">Categories</a>
            
            
            
            <a class="nav-item" href="/about">About</a>
            
            
            
            <a class="nav-item nav-item-github nav-item-icon" href="https://github.com/theonegis" target="_blank" aria-label="GitHub">&nbsp;</a>
            
            
            
            <a class="nav-item nav-item-search nav-item-icon" href="/search" target="_blank" aria-label="Search">&nbsp;</a>
            
            
        </div>
    </div>
</nav>
        
<article class="post">
    <div class="meta">
        
        <div class="categories text-uppercase">
        
            <a href="/categories/dl/">深度学习</a>
        
        </div>
        

        
        <div class="date" id="date">
            <span>March</span>
            <span>2,</span>
            <span>2019</span>
        </div>
        

        <h2 class="title">最简单的RNN回归模型入门(PyTorch)</h2>
    </div>

    <div class="divider"></div>

    <div class="content">
        <p>版权声明：本文为博主原创文章，转载请注明原文出处！<br>写作时间：2019-03-02 12:46:15</p>
<p>本文部分图片素材来自互联网，如有侵权，请联系作者删除！</p>
<h1 id="最简单的RNN回归模型入门（PyTorch版）"><a href="#最简单的RNN回归模型入门（PyTorch版）" class="headerlink" title="最简单的RNN回归模型入门（PyTorch版）"></a>最简单的RNN回归模型入门（PyTorch版）</h1><h2 id="RNN入门介绍"><a href="#RNN入门介绍" class="headerlink" title="RNN入门介绍"></a>RNN入门介绍</h2><p>至于RNN的能做什么，擅长什么，这里不赘述。如果不清楚，请先维基一下，那里比我说得更加清楚。</p>
<p>我们首先来来看一张经典的RNN模型示意图！</p>
<p><img src="/images/ml/Recurrent-Neural-Network.png" alt="Recurrent Neural Network"></p>
<p>图分左右两边：左边给出的RNN是一个抽象的循环结构，右边是左边RNN展开以后的形式。先来看右边的结构，从下往上依次是序列数据的输入X（图中的绿色结构，可以是时间序列，也可以是文本序列等等）。对于t时刻的x经过一个线性变换（U是变换的权重），然后与t-1时刻经过线性变换V的h相加，再经过一个 非线性激活（一般使用tanh或者relu函数）以后，形成一个t时刻的中间状态h，然后再经过一个线性变换（W）输出o ，最后再经过一个非线性激活（可以是sigmoid函数或者softmax等函数）形成最后的输出y。</p>
<p>上面的文字描述，可以形式化表示为下面的公式：</p>
<p>$$a^t = Vh^{t-1} + Ux^t + b \ h^t=tanh(a^t) \ o^t=Wh^t + c\ y^t=sigmoid(o^t)$$</p>
<p>是不是公式能比文字更加说明问题！</p>
<p>再来说左边的结构，坐标的结构表明后面地展开网络中的U，V，W参数都是在共享的，就是说不管我们的序列有多长，都是共享这一套参数的。这是RNN很重要的一个特性。</p>
<p>RNN的隐藏层可以有多层，但是RNN中我们的隐藏层一般不会设置太多，因为在横向上有很长的序列扩展形成的网络，这部分特征是我们更加关注的。最后，需要说明的是RNN可以是单向的，也可以是双向的。</p>
<h2 id="PyTorch中的RNN"><a href="#PyTorch中的RNN" class="headerlink" title="PyTorch中的RNN"></a>PyTorch中的RNN</h2><p>下面我们以一个最简单的回归问题使用正弦sin函数预测余弦cos函数，介绍如何使用PyTorch实现RNN模型。</p>
<p>先来看一下PyTorch中<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/nn.html#rnn">RNN</a>类的原型：</p>
<p><img src="/images/ml/RNNClass.png" alt="torch.nn.RNN"></p>
<ul>
<li>必选参数<code>input_size</code>指定输入序列中单个样本的大小尺寸，比如在NLP中我们可能用用一个10000个长度的向量表示一个单词，则这个<code>input_size</code>就是10000。在咱们的回归案例中，一个序列中包含若干点，而每个点的所代表的函数值（Y）作为一个样本，则咱们案例中的<code>input_size</code>为1。这个参数需要根据自己的实际问题确定。</li>
<li>必选参数<code>hidden_size</code>指的是隐藏层中输出特征的大小，这个是自定义的超参数。</li>
<li>必选参数<code>num_layers</code>指的是纵向的隐藏层的个数，根据实际问题我们一般可以选择1~10层。</li>
<li>可选参数<code>batch_first</code>指定是否将<code>batch_size</code>作为输入输出张量的第一个维度，如果是，则输入的尺寸为（<code>batch_size</code>， <code>seq_length</code>，<code>input_size</code>），否则，默认的顺序是（<code>seq_length</code>，<code>batch_size</code>， <code>input_size</code>）。</li>
<li>可选参数<code>bidirectional</code>指定是否使用双向RNN。</li>
</ul>
<p>下面再来说说RNN输入输出尺寸的问题，了解了这个可以让我们我们调试代码的时候更加清晰。下面是PyTorch官方的说明：</p>
<p><img src="/images/ml/RNNInOut.png" alt="RNN的输入输出"></p>
<p>对于RNN的输入包括输入序列和一个初始化的隐藏状态$h_0$。输入序列尺寸默认是（<code>sequence_length</code>，<code>batch_size</code>， <code>input_size</code>），所以如果我们的数据形式不是这样的，则需要手动调整为这种类型的格式。</p>
<p>隐藏状态$h_i$的尺寸是（<code>num_layers * num_directions</code>， <code>batch_size</code>，<code> hidden_size</code>）。单向RNN的<code>num_directions</code>为1，双向RNN的<code>num_directions</code>为2。</p>
<p>他们的尺寸为什么是这样的呢？这得根据本文开头的那个公式计算，即就是矩阵的相乘需要满足矩阵尺寸的关系，聪明的你想明白了吗？</p>
<p>输出的尺寸为 （<code>sequence_length</code>， <code>batch_size</code>， <code>num_directions * hidden_size</code>）</p>
<p>每一次RNN运行结果输出中还会附带输出中间隐藏状态$h_i$，当然这个尺寸和初始的隐藏状态相同。</p>
<p>下面以一个简单的例子说明怎么在程序中查看他们的尺寸：</p>
<pre><code class="Python">import torch
import torch.nn as nn

rnn = nn.RNN(10, 20, 2)
inputs = torch.randn(5, 3, 10)  # (time_step, batch_size, input_size)
h0 = torch.randn(2, 3, 20)  # (num_layers, batch_size, hidden_size)
output, hn = rnn(inputs, h0)
print(output.shape)  # (time_step, batch_size, hidden_size)

for name, param in rnn.named_parameters():
    if param.requires_grad:
        print(name, param.size())
</code></pre>
<p>其输出结果如下：</p>
<pre><code>torch.Size([5, 3, 20])
weight_ih_l0 torch.Size([20, 10])
weight_hh_l0 torch.Size([20, 20])
bias_ih_l0 torch.Size([20])
bias_hh_l0 torch.Size([20])
weight_ih_l1 torch.Size([20, 20])
weight_hh_l1 torch.Size([20, 20])
bias_ih_l1 torch.Size([20])
bias_hh_l1 torch.Size([20])
</code></pre>
<p>这里的<code>weight_ih_l0</code>表示的是RNN隐藏层第一层的权重U，<code>weight_hh_l0</code>表示的隐藏层第一层的权重V，类似的<code>bias</code>开头的表示偏置或者叫增益（我不知道中文如何翻译），以<code>l数字</code>结尾的表示第几层的权重或者偏置。</p>
<h2 id="代码实现与结果分析"><a href="#代码实现与结果分析" class="headerlink" title="代码实现与结果分析"></a>代码实现与结果分析</h2><p>好了，搞清楚了RNN的基本原理以及PyTorch中RNN类的输入输出参数要求，我们下面实现我们的回归案例。</p>
<p>比较重要的几个超参数是：<code>TIME_STEP</code>指定输入序列的长度（一个序列中包含的函数值的个数），<code>INPUT_SIZE</code>是1，表示一个序列中的每个样本包含一个函数值。</p>
<p>我们自定义的RNN类包含两个模型：一个<code>nn.RNN</code>层，一个<code>nn.Linear</code>层，注意<code>forward</code>函数的实现，观察每个变量的尺寸（注释中给出了答案）。</p>
<pre><code class="Python">import torch
from torch import nn
import numpy as np
import matplotlib.pyplot as plt

torch.manual_seed(2019)

# 超参设置
TIME_STEP = 10  # RNN时间步长
INPUT_SIZE = 1  # RNN输入尺寸
INIT_LR = 0.02  # 初始学习率
N_EPOCHS = 100  # 训练回数


class RNN(nn.Module):
    def __init__(self):
        super(RNN, self).__init__()
        self.rnn = nn.RNN(
            input_size=INPUT_SIZE,
            hidden_size=32,  # RNN隐藏神经元个数
            num_layers=1,  # RNN隐藏层个数
        )
        self.out = nn.Linear(32, 1)

    def forward(self, x, h):
        # x (time_step, batch_size, input_size)
        # h (n_layers, batch, hidden_size)
        # out (time_step, batch_size, hidden_size)
        out, h = self.rnn(x, h)
        prediction = self.out(out)
        return prediction, h


rnn = RNN()
print(rnn)

optimizer = torch.optim.Adam(rnn.parameters(), lr=INIT_LR)
loss_func = nn.MSELoss()
h_state = None  # 初始化隐藏层

plt.figure()
plt.ion()
for step in range(N_EPOCHS):
    start, end = step * np.pi, (step + 1) * np.pi  # 时间跨度
    # 使用Sin函数预测Cos函数
    steps = np.linspace(start, end, TIME_STEP, dtype=np.float32, endpoint=False)
    x_np = np.sin(steps)
    y_np = np.cos(steps)
    x = torch.from_numpy(x_np[:, np.newaxis, np.newaxis])  # 尺寸大小为(time_step, batch, input_size)
    y = torch.from_numpy(y_np[:, np.newaxis, np.newaxis])

    prediction, h_state = rnn(x, h_state)  # RNN输出（预测结果，隐藏状态）
    h_state = h_state.detach()  # 这一行很重要，将每一次输出的中间状态传递下去(不带梯度)
    loss = loss_func(prediction, y)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # 绘制中间结果
    plt.cla()
    plt.plot(steps, y_np, &#39;r-&#39;)
    plt.plot(steps, prediction.data.numpy().flatten(), &#39;b-&#39;)
    plt.draw()
    plt.pause(0.1)
plt.ioff()
plt.show()
</code></pre>
<p>最后的结果如下：</p>
<p><img src="/images/ml/RNNSinCos.gif" alt="RNN使用Sin预测Cos"></p>
<p>最后放一个当<code>TIME_STEP</code>分别等于10和20的最终预测结果的对比图：</p>
<p><img src="/images/ml/Time-Step-10.png" alt="RNN TIME_STEP等于10"></p>
<p><img src="/images/ml/Time-Step-20.png" alt="RNN TIME_STEP=20"></p>
<p>第一张是<code>TIME_STEP</code>=10的预测结果，第二张是<code>TIME_STEP</code>=20的预测结果。为什么当<code>TIME_STEP</code>=20的预测结果差得十万八千里呢？</p>
<p>这是因为经典的RNN存在梯度爆炸和梯度弥散问题（我尝试修剪了梯度可是结果还是很差，不知道是不是其它原因），对长时序的预测表现很不好，所以才有了后来的LSTM和GRU等RNN变种。实际现在已经很少使用经典RNN了。有时间在说说LSTM吧，欢迎关注！</p>

    </div>

    <!-- 
    <div class="about">
        <h1>About this Post</h1>
        <div class="details">
            <p>This post is written by 阿振, licensed under <a href="undefined">undefined</a>.</p>
        </div>
        
        <p class="tags">
            
            <i class="icon"></i>
            <a href="/tags/PyTorch/" class="tag">#PyTorch</a><a href="/tags/RNN/" class="tag">#RNN</a>
        </p>
        
    </div>
     -->

    <div class="container post-prev-next">
        
        <a href="/dl/%E9%80%9A%E4%BF%97LSTM%E9%95%BF%E7%9F%AD%E6%97%B6%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BB%8B%E7%BB%8D/" class="next">
            <div>
                <div class="text">
                    <p class="label">Next</p>
                    <h3 class="title">通俗LSTM长短时循环神经网络介绍</h3>
                </div>
            </div>
        </a>
        
        
        <a href="/algorithm/LeetCode-Longest-Palindromic-Subsequence/" class="prev">
            <div>
                <div class="text">
                    <p class="label">Previous</p>
                    <h3 class="title">LeetCode-Longest Palindromic Subsequence</>
                </div>
            </div>
        </a>
        
    </div>

    
        
        
    
</article>

        <footer>
    <div class="inner">
        <div class="links">
            
        </div>
        <div><h3>这个世界并不在乎你的自尊，只希望你在自我感觉良好之前有所作为！</h3></div>
        <span>&copy; 2023 阿振<br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> </span>
        
        
            <br>
            <div class="color-scheme-toggle" role="radiogroup" id="theme-color-scheme-toggle">
                <label>
                    <input type="radio" value="light">
                    <span>Light</span>
                </label>
                <label>
                    <input type="radio" value="dark">
                    <span>Dark</span>
                </label>
                <label>
                    <input type="radio" value="auto">
                    <span>Auto</span>
                </label>
            </div>
        
    </div>
</footer>


        
<script src="/js/main.js"></script>

        
        
        

        
        <script src="https://unpkg.com/scrollreveal"></script>
        <script>
            window.addEventListener('load', () => {
                ScrollReveal({ delay: 250, reset: true, easing: 'cubic-bezier(0, 0, 0, 1)' })
                ScrollReveal().reveal('.post-list-item .cover-img img')
                ScrollReveal().reveal('.post-list-item, .card, .content p img, .content .block-large img', { distance: '60px', origin: 'bottom', duration: 800 })
            })
        </script>
        
    </body>
</html>